{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanzania Water Pump- Machine Learning Analysis\n",
    "\n",
    "---\n",
    "\n",
    "### Explore several ML classification algorithms \n",
    "\n",
    "Predict whether a pump is functional, functional needing repair, or non-functional using data from [Taarifa](http://taarifa.org/) and [Tanzania Ministry of Water](http://maji.go.tz/) based on a number of variables about what kind of pump is operating, when it was installed, and how it is managed. A proper understanding of which water pumps are likely to fail could optimize maintenance operations and more reliably provide Tanzanian citizens with potable water.\n",
    "\n",
    "This predictive modeling challenge comes from [DrivenData](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/), an organization that helps non-profits by hosting data science competitions for social impact. The competition has open licensing: \"The data is available for use outside of DrivenData.\" The data was provided for a private Kaggle competition held as part of BloomTech's Data Science curriculum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, validation_curve\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from xgboost import XGBClassifier\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Load and Clean Data\n",
    "Using the information and understanding obtained from the EDA notebook, a 'wrangle()' function was written to perform the same pre-processing operations on both the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(feature_path, target_path=None):\n",
    "    \"\"\"\n",
    "        This function loads and cleans data for feature matrix and target vector\n",
    "        .csv files. The cleaning tasks include:\n",
    "            - Replace erroneously low latitude values with NaNs\n",
    "            - Convert datatypes\n",
    "            - Remove unnecessary columns\n",
    "            - Remove high-cardinality categorical columns (HCCCs)\n",
    "            - Remove duplicate columns\n",
    "        \n",
    "        Input: filepath\n",
    "        Output: pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    if target_path:\n",
    "        df = pd.merge(pd.read_csv(feature_path,\n",
    "                                  na_values=[0, -2.000000e-08],\n",
    "                                  parse_dates=['date_recorded']),\n",
    "                      pd.read_csv(target_path)).set_index('id')\n",
    "\n",
    "    else:\n",
    "        df = pd.read_csv(feature_path,\n",
    "                         na_values=-2.000000e-08,\n",
    "                         parse_dates=['date_recorded'],\n",
    "                         index_col='id')\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    df.drop(columns=['region_code',\n",
    "                     'district_code',\n",
    "                     'recorded_by',\n",
    "                     'scheme_management'\n",
    "                     'extraction_type_group',\n",
    "                     'extraction_type_class',\n",
    "                     'payment_type',\n",
    "                     'quality_group',\n",
    "                     'quantity_group',\n",
    "                     'source'\n",
    "                     'source_group',\n",
    "                     'waterpoint_type_group'], inplace=True)\n",
    "\n",
    "    # Remove HCCCs (columns with over 100 different categories)\n",
    "    cutoff = 100\n",
    "    drop_cols = [col for col in df.select_dtypes('object').columns \n",
    "                if df[col].nunique() > cutoff]\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "\n",
    "    return df\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Establish Baseline\n",
    "\n",
    "Accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Build and Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Check Evaluation Metrics\n",
    "\n",
    "Compare with baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Tune Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Communicate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future thing could be changing how HCCCs are handled. Rather than just dropping the columns, we could reduce the cardinality of each feature by aggregating the categories, using an \"other\" field.\n",
    "\n",
    "Try undersampling or oversampling because the proportion of functional to non-functional pumps is not even"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('U2-ML': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0465ebcb37716cb48e7502240deaccee8cfa6fc7eb7ef0195569c351e696f5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
